{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"depth_DNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q-NyX3YZAE-n","colab_type":"text"},"source":["## Prerequisites\n","\n","\n","Make sure you have the following packages installed before running the notebook cells:\n"," - NumPy\n"," - Keras\n"," - Tensorflow\n"," - pydot\n"," - graphviz\n"," - matplotlib"]},{"cell_type":"code","metadata":{"id":"wORojLIVAE-o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595490257326,"user_tz":-330,"elapsed":3315,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"8f892d65-668b-4e30-d3e1-baaafbcaabbb"},"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import keras.backend as K\n","from keras import (layers, models, \n","                   optimizers)\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.vis_utils import plot_model\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"z7Eg8sJxAE-r","colab_type":"code","colab":{}},"source":["SEED = 9\n","BATCH_SIZE = 64\n","np.random.seed(SEED)\n","tf.set_random_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rvwQlnVHWHx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595490277560,"user_tz":-330,"elapsed":9217,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"8f6244a4-798f-41ee-a47e-95bf605e9260"},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XB7sDFMZue4I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1573113110774,"user_tz":-330,"elapsed":28928,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"c59d3d0b-fad1-43fe-cf90-6b45f2c5328d"},"source":["# import subprocess\n","# subprocess.call(['unzip', '/content/drive/My Drive/Colab Notebooks/new_art.zip', '-d', '/content/drive/My Drive/Colab Notebooks/new_art'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"LFadxfd18W97","colab_type":"code","colab":{}},"source":["# import shutil\n","# shutil.rmtree('/content/depth_data/images')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNANEIjZMWA3","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yb5jWflrAE-t","colab_type":"text"},"source":["### Normalisation."]},{"cell_type":"code","metadata":{"id":"iyOBUf-6AE-u","colab_type":"code","colab":{}},"source":["MEAN = \"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/IMG_depth_mean.npz\"\n","STD = \"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/IMG_depth_std.npz\"\n","\n","mean = np.load(MEAN)['mean']\n","std = np.load(STD)['std']\n","\n","# mean = np.reshape(mean, (128, 128, 3))\n","# std = np.reshape(std, (128, 128, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKJymUcMAE-w","colab_type":"code","colab":{}},"source":["def unet_generator(gen1, gen2):\n","    \n","    while True:\n","        im_op = next(gen1)\n","        mask_op = next(gen2)\n","        \n","        yield [im_op, mask_op]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqvAy4t-AE-y","colab_type":"code","colab":{}},"source":["# from preprocessing.image import ImageDataGenerator\n","\n","def preprocess(x):\n","    return (x - mean)/(std + K.epsilon())\n","\n","# For train\n","\n","# IMP: ENSURE THAT AUGMENTATIONS ARE CONSISTENT!\n","\n","# Base augmentations\n","base_augmentations = dict (\n","    horizontal_flip = True,\n","    vertical_flip = True,\n","    rotation_range = 60,\n","    height_shift_range = 0.1,\n","    width_shift_range = 0.1\n",")\n","\n","# Make a copy.\n","im_augmentations = dict(base_augmentations)\n","mask_augmentations = dict(base_augmentations)\n","\n","# Add the preprocessing step.\n","im_augmentations[\"preprocessing_function\"] = preprocess\n","# mask_augmentations[\"rescale\"] = 1./255\n","\n","im_gen = ImageDataGenerator(**im_augmentations)\n","mask_gen = ImageDataGenerator(**mask_augmentations)\n","\n","# -------------------------------------------------\n","\n","# For val and test\n","im_gen_no_augment = ImageDataGenerator(preprocessing_function=preprocess)\n","# mask_gen_no_augment = ImageDataGenerator(rescale=1./255)\n","mask_gen_no_augment = ImageDataGenerator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVJXi0M0AE-z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578981194784,"user_tz":-330,"elapsed":830,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"10d376eb-6b92-4b85-8d62-fa713a5c3f3c"},"source":["im_gen"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.preprocessing.image.ImageDataGenerator at 0x7f39da1814a8>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"qqOUwSCAAE-2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578981196111,"user_tz":-330,"elapsed":1986,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"7cfa3c85-7aa1-456f-cd4e-0e3b1075b40f"},"source":["mask_gen"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.preprocessing.image.ImageDataGenerator at 0x7f39da17ce80>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"XmpJQEfmAE-4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1578981426119,"user_tz":-330,"elapsed":1861,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"92f65167-3b8f-44e5-d7c0-ca9d0112dd99"},"source":["# print()\n","print(\"Train:\")\n","\n","# ====== Train generators ====== #\n","im_train_gen = im_gen.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/images/\", \n","                                          classes=[\"train\"], \n","                                          target_size=(128, 128),\n","                                          seed=SEED, \n","                                          batch_size=BATCH_SIZE, \n","                                          class_mode=None, \n","                                          shuffle=True)\n","\n","mask_train_gen = mask_gen.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/masks/\", \n","                                              classes=[\"train\"], \n","                                              target_size=(128, 128),\n","                                              seed=SEED, \n","                                              batch_size=BATCH_SIZE, \n","                                              class_mode=None,\n","                                              shuffle=True, \n","                                              color_mode='grayscale')\n","\n","train_gen = unet_generator(im_train_gen, mask_train_gen)\n","\n","# ====== Validation generators ====== #\n","\n","print()\n","print(\"Validation:\")\n","\n","im_val_gen = im_gen_no_augment.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/images/\", \n","                                                   classes=[\"val\"], \n","                                                   target_size=(128, 128),\n","                                                   seed=SEED, \n","                                                   batch_size=BATCH_SIZE, \n","                                                   class_mode=None, \n","                                                   shuffle=True)\n","\n","mask_val_gen = mask_gen_no_augment.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/masks/\", \n","                                                       classes=[\"val\"], \n","                                                       target_size=(128, 128),\n","                                                       seed=SEED, \n","                                                       batch_size=BATCH_SIZE, \n","                                                       class_mode=None,\n","                                                       shuffle=True,\n","                                                       color_mode='grayscale')\n","\n","val_gen = unet_generator(im_val_gen, mask_val_gen)\n","\n","# ====== Test generators ====== #\n","\n","print()\n","print(\"Test:\")\n","\n","im_test_gen = im_gen_no_augment.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/images/\", \n","                                                    classes=[\"test\"], \n","                                                    target_size=(128, 128),\n","                                                    seed=SEED, \n","                                                    batch_size=BATCH_SIZE, \n","                                                    class_mode=None, \n","                                                    shuffle=True,)\n","\n","mask_test_gen = mask_gen_no_augment.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/depth_data/depth_data/masks/\", \n","                                                        classes=[\"test\"], \n","                                                        target_size=(128, 128),\n","                                                        seed=SEED, \n","                                                        batch_size=BATCH_SIZE, \n","                                                        class_mode=None,\n","                                                        shuffle=True, \n","                                                        color_mode='grayscale')\n","\n","test_gen = unet_generator(im_test_gen, mask_test_gen)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train:\n","Found 1599 images belonging to 1 classes.\n","Found 1599 images belonging to 1 classes.\n","\n","Validation:\n","Found 343 images belonging to 1 classes.\n","Found 343 images belonging to 1 classes.\n","\n","Test:\n","Found 342 images belonging to 1 classes.\n","Found 342 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"09qVSbFTAE-5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1578981198298,"user_tz":-330,"elapsed":3811,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"2ad7babb-1028-49b3-a38b-1f790aa3bce3"},"source":["print(len(next(train_gen)))\n","print(np.shape(next(train_gen)[0]))\n","print(np.shape(next(train_gen)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2\n","(64, 128, 128, 3)\n","(64, 128, 128, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bGelb8aZAE-7","colab_type":"code","colab":{}},"source":["from keras.layers import Dropout\n","from keras import regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"4434m_0tAE--","colab_type":"code","colab":{}},"source":["def UNet():\n","    _in_ = layers.Input(shape=(128, 128, 3))\n","    reg = 1e-3\n","    drop = 0.55\n","    c=1\n","    _alpha = 0.1\n","    # 120, 120, 8\n","    x = layers.Conv2D(8*c,\n","                      kernel_size=(3, 3),\n","                      strides=(1, 1),\n","                      padding=\"same\",\n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(_in_)\n","    x = layers.BatchNormalization()(x)\n","    # out1 = layers.Activation(\"relu\", name=\"out1\")(x)\n","    out1 = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 60, 60, 8\n","    x = layers.MaxPooling2D(pool_size=(2, 2),\n","                            strides=(2, 2),\n","                            padding=\"same\")(out1)\n","    x = layers.BatchNormalization()(x)\n","#     x = Dropout(drop)(x)\n","    # x = layers.Activation(\"relu\")(x)\n","    \n","    # 60, 60, 16\n","    x = layers.Conv2D(16*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1),\n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    out2 = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","    # 30, 30, 16\n","    x = layers.MaxPooling2D(pool_size=(2, 2),\n","                            strides=(2, 2),\n","                            padding=\"same\")(out2)\n","    x = layers.BatchNormalization()(x)\n","#     x = Dropout(drop)(x)\n","    # x = layers.Activation(\"relu\")(x)\n","    \n","    \n","    # 30, 30, 32\n","    x = layers.Conv2D(32*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1),\n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    out3 = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","    # 15, 15, 32\n","    x = layers.MaxPooling2D(pool_size=(2, 2),\n","                            strides=(2, 2),\n","                            padding=\"same\")(out3)\n","    x = layers.BatchNormalization()(x)\n","    # x = Dropout(drop)(x)\n","    # x = layers.Activation(\"relu\")(x)\n","    \n","    # 15, 15, 64\n","    x = layers.Conv2D(64*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1),\n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    out4 = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","\n","    # 15, 15, 32\n","    x = layers.MaxPooling2D(pool_size=(2, 2),\n","                            strides=(2, 2),\n","                            padding=\"same\")(out4)\n","    x = layers.BatchNormalization()(x)\n","    # x = Dropout(drop)(x)\n","    # x = layers.Activation(\"relu\")(x)\n","    \n","    # 15, 15, 64\n","    x = layers.Conv2D(128*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1),\n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    out5 = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","\n","    # 15, 15, 32\n","    x = layers.MaxPooling2D(pool_size=(2, 2),\n","                            strides=(2, 2),\n","                            padding=\"same\")(out5)\n","    x = layers.BatchNormalization()(x)\n","    # x = Dropout(drop)(x)\n","    # x = layers.Activation(\"relu\")(x)\n","    \n","    # 15, 15, 64\n","    x = layers.Conv2D(256*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1),\n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","    # Upscaling begins here.\n","\n","        # 30, 30, 32\n","    x = layers.Conv2DTranspose(128*c, \n","                               kernel_size=(2, 2), \n","                               strides=(2, 2), \n","                               padding=\"same\",\n","                               use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Concatenate(axis=-1)([x, out5])\n","    # x = Dropout(drop)(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 30, 30, 32\n","    x = layers.Conv2D(128*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","         # 30, 30, 32\n","    x = layers.Conv2DTranspose(64*c, \n","                               kernel_size=(2, 2), \n","                               strides=(2, 2), \n","                               padding=\"same\",\n","                               use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Concatenate(axis=-1)([x, out4])\n","    # x = Dropout(drop)(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 30, 30, 32\n","    x = layers.Conv2D(64*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","    \n","    \n","    # 30, 30, 32\n","    x = layers.Conv2DTranspose(32*c, \n","                               kernel_size=(2, 2), \n","                               strides=(2, 2), \n","                               padding=\"same\",\n","                               use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Concatenate(axis=-1)([x, out3])\n","#     x = Dropout(drop)(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 30, 30, 32\n","    x = layers.Conv2D(32*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","#     x = Dropout(0.3)(x)\n","    \n","    # 60, 60, 16\n","    x = layers.Conv2DTranspose(16*c, \n","                               kernel_size=(2, 2), \n","                               strides=(2, 2), \n","                               padding=\"same\",\n","                               use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Concatenate(axis=-1)([x, out2])\n","    # x = Dropout(drop)(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 60, 60, 16\n","    x = layers.Conv2D(16*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","\n","    \n","    # 120, 120, 8\n","    x = layers.Conv2DTranspose(8*c, \n","                               kernel_size=(2, 2), \n","                               strides=(2, 2), \n","                               padding=\"same\",\n","                               use_bias=False)(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Concatenate(axis=-1)([x, out1])\n","    # x = Dropout(drop)(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","    \n","    # 120, 120, 3\n","    x = layers.Conv2D(3*c, \n","                      kernel_size=(3, 3), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False,\n","                      kernel_regularizer=regularizers.l2(reg))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(alpha = _alpha)(x)\n","\n","    \n","#     120, 120, 1\n","    x = layers.Conv2D(1, \n","                      kernel_size=(1, 1), \n","                      strides=(1, 1), \n","                      padding=\"same\", \n","                      use_bias=False)(x)\n","\n","    \n","    _out_ = layers.Activation('relu')(x)\n","    \n","    return models.Model(_in_, _out_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nk8Eg2VmAE_A","colab_type":"code","colab":{}},"source":["model = UNet()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Y0emLL8mAE_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1578981201368,"user_tz":-330,"elapsed":6179,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"e54e4a70-84db-4186-a311-09f66850daba"},"source":["  print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 128, 128, 8)  216         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 128, 128, 8)  32          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 8)    0           leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 64, 64, 8)    32          max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 64, 16)   1152        batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 64, 64, 16)   64          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 64, 64, 16)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 16)   0           leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 32)   4608        batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 32, 32, 32)   128         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 32, 32, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 32)   0           leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 64)   18432       batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 64)     0           leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_9[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 8, 8, 128)    73728       batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 8, 8, 128)    0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 128)    0           leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 4, 4, 128)    512         max_pooling2d_10[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 4, 4, 256)    294912      batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 4, 4, 256)    1024        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 4, 4, 256)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_6 (Conv2DTrans (None, 8, 8, 128)    131072      leaky_re_lu_22[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_transpose_6[0][0]         \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 8, 8, 256)    0           batch_normalization_33[0][0]     \n","                                                                 leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 8, 8, 256)    0           concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 8, 8, 128)    294912      leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_7 (Conv2DTrans (None, 16, 16, 64)   32768       leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 16, 16, 64)   256         conv2d_transpose_7[0][0]         \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 16, 16, 128)  0           batch_normalization_35[0][0]     \n","                                                                 leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 16, 16, 128)  0           concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 64)   73728       leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_8 (Conv2DTrans (None, 32, 32, 32)   8192        leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 32, 32, 32)   128         conv2d_transpose_8[0][0]         \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 64)   0           batch_normalization_37[0][0]     \n","                                                                 leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 32, 32, 64)   0           concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 32, 32, 32)   18432       leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 32, 32, 32)   128         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 32, 32, 32)   0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_9 (Conv2DTrans (None, 64, 64, 16)   2048        leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 64, 64, 16)   64          conv2d_transpose_9[0][0]         \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 64, 64, 32)   0           batch_normalization_39[0][0]     \n","                                                                 leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 64, 64, 32)   0           concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 64, 64, 16)   4608        leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 64, 64, 16)   64          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 64, 64, 16)   0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_10 (Conv2DTran (None, 128, 128, 8)  512         leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 128, 128, 8)  32          conv2d_transpose_10[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 128, 128, 16) 0           batch_normalization_41[0][0]     \n","                                                                 leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 128, 128, 16) 0           concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 128, 128, 3)  432         leaky_re_lu_31[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 128, 128, 3)  12          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 128, 128, 3)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 128, 128, 1)  3           leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 128, 128, 1)  0           conv2d_24[0][0]                  \n","==================================================================================================\n","Total params: 964,727\n","Trainable params: 962,241\n","Non-trainable params: 2,486\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lzVCSb6AE_E","colab_type":"code","colab":{}},"source":["# plot_model(model=model, \n","#            to_file=\"unet2.png\", \n","#            show_shapes=True, \n","#            show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnH1anB5AE_G","colab_type":"code","colab":{}},"source":["def dice_coefficient(y_true, y_pred):\n","    \n","    num_axes = len(K.int_shape(y_true))\n","    \n","    axes = list(range(1, num_axes))\n","    \n","    numerator = 2. * K.sum(y_true * y_pred, axis=axes)\n","    denominator = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes)\n","    \n","    return K.mean(numerator/(denominator + K.epsilon()), axis=0)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1. - dice_coefficient(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"myDuVFQqAE_H","colab_type":"code","colab":{}},"source":["def depth_loss_function(y_true, y_pred, theta=0.85, maxDepthVal=1000.0/10.0):\n","    \n","    # Point-wise depth\n","    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n","\n","    # Edges\n","    dy_true, dx_true = tf.image.image_gradients(y_true)\n","    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n","    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n","\n","    # Structural similarity (SSIM) index\n","    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n","\n","    # Weights\n","    w1 = 0.08\n","    w2 = 0.07\n","    w3 = theta\n","\n","    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tma2hAs1AE_J","colab_type":"code","colab":{}},"source":["from keras.losses import mean_squared_error, categorical_crossentropy\n","from keras.utils import to_categorical\n","def cat_loss(y_true, y_pred):\n","  y_true_cat=to_categorical(y_true)\n","  y_true = y_true_cat.reshape(y_true.shape[0], y_true.shape[1], y_true_cat.shape[1])\n","  y_true=tf.argmax(y_true,axis=-1)\n","  y_pred_cat=to_categorical(y_pred)\n","  y_pred = y_pred_cat.reshape(y_pred.shape[0], y_pred.shape[1], y_true_cat.shape[1])\n","  y_pred=tf.argmax(y_pred,axis=-1)\n","  return K.mean(categorical_crossentropy(y_true, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiScy8gFP3xZ","colab_type":"code","colab":{}},"source":["import keras.losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mV2Jy8h0AE_L","colab_type":"code","colab":{}},"source":["from keras.metrics import mean_squared_error as accuracy\n","def acc(y_true, y_pred):\n","    return K.mean(accuracy(y_true, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WzEnoJVAE_N","colab_type":"code","colab":{}},"source":["def combined_loss(y_true, y_pred):\n","    rms_wt = 0\n","    depth_wt = 1\n","    return rms_wt * acc(y_true, y_pred) + depth_wt * depth_loss_function(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvgpHao7AE_P","colab_type":"code","colab":{}},"source":["# optim = optimizers.sgd(lr=.1, decay=3e-4, momentum=0.99)\n","optim = optimizers.adam(lr=7e-2, decay=3e-4)\n","# optim = optimizers.Adadelta()\n","\n","model.compile(loss=combined_loss, metrics=[combined_loss], optimizer=optim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU94HmEzAE_U","colab_type":"code","colab":{}},"source":["from keras.callbacks import LearningRateScheduler\n","\n","decay_interval = 2\n","decay_intensity = 0.6\n","\n","def schedule(epoch, lr):\n","    if epoch > 0 and (epoch+1)%decay_interval==0:\n","        lr *= decay_intensity\n","    \n","    return lr\n","\n","scheduler = LearningRateScheduler(schedule, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9azMfwAAE_X","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","\n","checkpoint_name = \"UNet_depth_best_val_loss.h5\"\n","\n","checkpointer = ModelCheckpoint(checkpoint_name,\n","                               monitor='val_loss', mode='min', \n","                               save_best_only=True, \n","                               save_weights_only=False, \n","                               verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MboS84erAE_Z","colab_type":"code","colab":{}},"source":["import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"XSy36ccUAE_b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1578982775619,"user_tz":-330,"elapsed":1079372,"user":{"displayName":"anurag palkar","photoUrl":"","userId":"09472476734106652763"}},"outputId":"308ff6a2-5b83-472c-d384-964e6f7c44b4"},"source":["%%time\n","# Fit.\n","num_epochs = 20\n","train_steps = (im_train_gen.samples//BATCH_SIZE) + (im_train_gen.samples%BATCH_SIZE!=0)\n","val_steps = (im_val_gen.samples//BATCH_SIZE) + (im_val_gen.samples%BATCH_SIZE!=0)\n","\n","h = model.fit_generator(train_gen, \n","                        steps_per_epoch=train_steps, \n","                        validation_data=val_gen, \n","                        validation_steps=val_steps, \n","                        epochs=num_epochs, \n","                        shuffle=True, \n","                        verbose=1, \n","                        callbacks=[scheduler, checkpointer],\n","                        use_multiprocessing = True)\n","\n","print(\"Done Training\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","\n","Epoch 00001: LearningRateScheduler setting learning rate to 0.07000000029802322.\n","13/25 [==============>...............] - ETA: 25s - loss: 76.9645 - combined_loss: 76.6995"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:709: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n","  UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["25/25 [==============================] - 673s 27s/step - loss: 72.2211 - combined_loss: 71.9662 - val_loss: 76.0952 - val_combined_loss: 75.8898\n","\n","Epoch 00001: val_loss improved from inf to 76.09524, saving model to UNet_depth_best_val_loss.h5\n","Epoch 2/20\n","\n","Epoch 00002: LearningRateScheduler setting learning rate to 0.04200000017881393.\n","25/25 [==============================] - 13s 507ms/step - loss: 54.3096 - combined_loss: 54.0829 - val_loss: 36.2942 - val_combined_loss: 35.8634\n","\n","Epoch 00002: val_loss improved from 76.09524 to 36.29421, saving model to UNet_depth_best_val_loss.h5\n","Epoch 3/20\n","\n","Epoch 00003: LearningRateScheduler setting learning rate to 0.041999999433755875.\n","25/25 [==============================] - 20s 807ms/step - loss: 42.2093 - combined_loss: 41.6861 - val_loss: 88.6462 - val_combined_loss: 87.7138\n","\n","Epoch 00003: val_loss did not improve from 36.29421\n","Epoch 4/20\n","\n","Epoch 00004: LearningRateScheduler setting learning rate to 0.025199999660253523.\n","25/25 [==============================] - 21s 836ms/step - loss: 36.4028 - combined_loss: 35.3356 - val_loss: 39.9754 - val_combined_loss: 38.4938\n","\n","Epoch 00004: val_loss did not improve from 36.29421\n","Epoch 5/20\n","\n","Epoch 00005: LearningRateScheduler setting learning rate to 0.025200000032782555.\n","25/25 [==============================] - 21s 838ms/step - loss: 33.8847 - combined_loss: 32.6741 - val_loss: 40.3637 - val_combined_loss: 39.2448\n","\n","Epoch 00005: val_loss did not improve from 36.29421\n","Epoch 6/20\n","\n","Epoch 00006: LearningRateScheduler setting learning rate to 0.015120000019669531.\n","25/25 [==============================] - 21s 838ms/step - loss: 32.7124 - combined_loss: 31.8449 - val_loss: 35.6110 - val_combined_loss: 34.8944\n","\n","Epoch 00006: val_loss improved from 36.29421 to 35.61105, saving model to UNet_depth_best_val_loss.h5\n","Epoch 7/20\n","\n","Epoch 00007: LearningRateScheduler setting learning rate to 0.015119999647140503.\n","25/25 [==============================] - 20s 818ms/step - loss: 31.7144 - combined_loss: 31.0110 - val_loss: 34.1059 - val_combined_loss: 33.3835\n","\n","Epoch 00007: val_loss improved from 35.61105 to 34.10586, saving model to UNet_depth_best_val_loss.h5\n","Epoch 8/20\n","\n","Epoch 00008: LearningRateScheduler setting learning rate to 0.009071999788284301.\n","25/25 [==============================] - 21s 857ms/step - loss: 31.2266 - combined_loss: 30.5563 - val_loss: 32.4445 - val_combined_loss: 31.8261\n","\n","Epoch 00008: val_loss improved from 34.10586 to 32.44450, saving model to UNet_depth_best_val_loss.h5\n","Epoch 9/20\n","\n","Epoch 00009: LearningRateScheduler setting learning rate to 0.009072000160813332.\n","25/25 [==============================] - 21s 832ms/step - loss: 30.7384 - combined_loss: 30.1097 - val_loss: 32.3423 - val_combined_loss: 31.7219\n","\n","Epoch 00009: val_loss improved from 32.44450 to 32.34228, saving model to UNet_depth_best_val_loss.h5\n","Epoch 10/20\n","\n","Epoch 00010: LearningRateScheduler setting learning rate to 0.005443200096487999.\n","25/25 [==============================] - 20s 811ms/step - loss: 30.4681 - combined_loss: 29.8734 - val_loss: 31.9233 - val_combined_loss: 31.3645\n","\n","Epoch 00010: val_loss improved from 32.34228 to 31.92331, saving model to UNet_depth_best_val_loss.h5\n","Epoch 11/20\n","\n","Epoch 00011: LearningRateScheduler setting learning rate to 0.0054432000033557415.\n","25/25 [==============================] - 20s 816ms/step - loss: 30.2240 - combined_loss: 29.6746 - val_loss: 33.3641 - val_combined_loss: 32.8167\n","\n","Epoch 00011: val_loss did not improve from 31.92331\n","Epoch 12/20\n","\n","Epoch 00012: LearningRateScheduler setting learning rate to 0.003265920002013445.\n","25/25 [==============================] - 21s 840ms/step - loss: 29.9414 - combined_loss: 29.4090 - val_loss: 33.5587 - val_combined_loss: 33.0394\n","\n","Epoch 00012: val_loss did not improve from 31.92331\n","Epoch 13/20\n","\n","Epoch 00013: LearningRateScheduler setting learning rate to 0.0032659200951457024.\n","25/25 [==============================] - 21s 838ms/step - loss: 29.7551 - combined_loss: 29.2375 - val_loss: 34.3475 - val_combined_loss: 33.8349\n","\n","Epoch 00013: val_loss did not improve from 31.92331\n","Epoch 14/20\n","\n","Epoch 00014: LearningRateScheduler setting learning rate to 0.0019595520570874214.\n","25/25 [==============================] - 21s 830ms/step - loss: 29.3741 - combined_loss: 28.8685 - val_loss: 34.1097 - val_combined_loss: 33.6126\n","\n","Epoch 00014: val_loss did not improve from 31.92331\n","Epoch 15/20\n","\n","Epoch 00015: LearningRateScheduler setting learning rate to 0.0019595520570874214.\n","25/25 [==============================] - 21s 839ms/step - loss: 29.3394 - combined_loss: 28.8447 - val_loss: 33.7864 - val_combined_loss: 33.2943\n","\n","Epoch 00015: val_loss did not improve from 31.92331\n","Epoch 16/20\n","\n","Epoch 00016: LearningRateScheduler setting learning rate to 0.001175731234252453.\n","25/25 [==============================] - 21s 835ms/step - loss: 28.9922 - combined_loss: 28.5028 - val_loss: 32.7170 - val_combined_loss: 32.2314\n","\n","Epoch 00016: val_loss did not improve from 31.92331\n","Epoch 17/20\n","\n","Epoch 00017: LearningRateScheduler setting learning rate to 0.0011757311876863241.\n","25/25 [==============================] - 21s 833ms/step - loss: 29.0727 - combined_loss: 28.5896 - val_loss: 33.1372 - val_combined_loss: 32.6552\n","\n","Epoch 00017: val_loss did not improve from 31.92331\n","Epoch 18/20\n","\n","Epoch 00018: LearningRateScheduler setting learning rate to 0.0007054387126117944.\n","25/25 [==============================] - 21s 838ms/step - loss: 28.9916 - combined_loss: 28.5105 - val_loss: 33.1162 - val_combined_loss: 32.6359\n","\n","Epoch 00018: val_loss did not improve from 31.92331\n","Epoch 19/20\n","\n","Epoch 00019: LearningRateScheduler setting learning rate to 0.0007054387242533267.\n","25/25 [==============================] - 21s 836ms/step - loss: 28.7077 - combined_loss: 28.2282 - val_loss: 32.3422 - val_combined_loss: 31.8638\n","\n","Epoch 00019: val_loss did not improve from 31.92331\n","Epoch 20/20\n","\n","Epoch 00020: LearningRateScheduler setting learning rate to 0.000423263234551996.\n","25/25 [==============================] - 21s 840ms/step - loss: 28.4698 - combined_loss: 27.9918 - val_loss: 33.1892 - val_combined_loss: 32.7118\n","\n","Epoch 00020: val_loss did not improve from 31.92331\n","Done Training\n","CPU times: user 1min 42s, sys: 24.7 s, total: 2min 6s\n","Wall time: 17min 58s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6h-tD255AE_d","colab_type":"code","colab":{}},"source":["# Plot the curves.\n","fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n","\n","# Dice loss.\n","ax[0].plot(h.history['loss'], 'r-')\n","ax[0].plot(h.history['val_loss'], 'b-')\n","ax[0].set_xlabel(\"Epochs\")\n","ax[0].set_ylabel(\"Dice Loss\")\n","ax[0].legend([\"Training Dice loss\", \"Validation Dice loss\"])\n","\n","ax[1].plot(h.history['combined_loss'], 'r-')\n","ax[1].plot(h.history['val_combined_loss'], 'b-')\n","ax[1].set_xlabel(\"Epochs\")\n","ax[1].set_ylabel(\"Dice Coefficient\")\n","ax[1].legend([\"Training Dice Coefficient\", \"Validation Dice Coefficient\"])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgqwovyjAE_f","colab_type":"code","colab":{}},"source":["model.load_weights(\"/content/UNet_depth_best_val_loss.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"tKOgksJ0AE_h","colab_type":"code","colab":{}},"source":["num_outputs = 10\n","\n","fig, ax = plt.subplots(nrows=num_outputs, ncols=3, figsize=(15, 25))\n","\n","batch = next(test_gen)\n","# file_names = next(im_test_gen)\n","\n","for ix in range(num_outputs):\n","    # 120, 120, 3\n","    im = batch[0][ix,:]\n","    \n","    # De-normalize image.\n","    im = np.clip((im * std) + mean, 0, 255).astype(np.uint8)\n","    \n","    # 120, 120, 1\n","    mask = batch[1][ix,:]\n","    \n","    # 1, 120, 120, 3\n","    im_pred = np.expand_dims(im, axis=0)\n","    \n","    # 1, 120, 120, 1\n","    pred = model.predict(im_pred)\n","    \n","#     print(pred)\n","    \n","    # 120, 120, 3\n","    pred = np.squeeze(pred, axis=0)\n","    \n","    # 120, 120, 1 -> 120, 120\n","    mask = np.squeeze(mask, axis=-1)\n","    \n","    # 120, 120, 1 -> 120, 120\n","    pred = np.squeeze(pred, axis=-1)\n","#     pred = ((pred/pred.max())**1.3)\n","#     pred = ((pred/pred.max())*255)\n","    \n","    ax[ix, 0].imshow(im)\n","    ax[ix, 1].imshow(mask, cmap='gray')\n","    ax[ix, 2].imshow(pred, cmap='gray')\n","#     ax[ix, 0].set_xlabel(file_names[ix])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2DgFfqVAE_k","colab_type":"code","colab":{}},"source":["for i, l in enumerate(model.get_weights()):\n","  if len(l.shape) > 2:\n","    print(l.shape, i, l.min(), l.max())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ziPqjjiAE_m","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Khgq4X76AE_n","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","imb = np.random.randint(120, 250, (100,100,100)).astype('uint8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ji0jZKV4Sq8g","colab_type":"code","colab":{}},"source":["def on_trackbar(img_no):\n","    img = imb[img_no, :, :].astype('uint8')\n","    img = cv2.putText(img, str(5), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, .4, (0,255,255), 2)\n","    cv2_imshow(\"CT Labeled\", img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"urhcLPynAE_p","colab_type":"code","colab":{}},"source":["trackbar_name = \"CT #\"\n","title_window = \"CT Labeled\"\n","cv2.namedWindow(title_window)\n","# cv2.createTrackbar(trackbar_name, title_window , 0, img.shape[0] - 1, on_trackbar)\n","cv2.createTrackbar(trackbar_name, title_window , 0, 99, on_trackbar)\n","on_trackbar(0)\n","while show==True:\n","        k = cv2.waitKey(1) & 0xFF\n","        #exit\n","        if k == ord('x') or k == ord('X'):\n","            show = False\n","        if k == ord('q') or k == ord('Q'):\n","            show = False\n","            cv2.destroyAllWindows()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7JB_gLWpSPNF","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KNG5YwDT7rB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}